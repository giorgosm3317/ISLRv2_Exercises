---
title: "Chapter 3 - Exercises"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, options(scipen = 1, digits = 2))

```

```{r results = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(broom)
```


## Exercise 8 

This question involves the use of simple linear regression on the Auto data set.

a. Use the lm() function to perform a simple linear regression with mpg as the response and horsepower as the predictor. Use the summary() function to print the results. Comment on the output. For example:

    i. Is there a relationship between the predictor and the response?
    i. How strong is the relationship between the predictor and the response?
    i. Is the relationship between the predictor and the response positive or negative?
    i. What is the predicted mpg associated with a horsepower of 98? What are the associated 95 % confidence and prediction intervals?
    
b. Plot the response and the predictor. Use the abline() function to display the least squares regression line.

c. Use the plot() function to produce diagnostic plots of the least squares regression fit. Comment on any problems you see with the fit.

### Answer

a. We fit the model: 

```{r}
auto_fit <- lm(mpg ~ horsepower, data = ISLR2::Auto)
summary(auto_fit)
```

Based on the above:

i. We examine if there is a relationship between the predictor and the response by testing the null hypothesis that all the regression coefficients are zero i.e. \[ H_0: {\beta}_{1} = {\beta}_2 = {\beta}_p = 0 \] versus the alternative \[H_a: at \; least \; one \; {\beta}_j \; is \; non-zero \]
    Since the F-statistic = `r auto_fit %>% glance() %>% pull(statistic)` with a p-value = `r auto_fit %>% glance() %>% pull(p.value)`, we reject the null hypothesis and we conclude there is indeed a relationship between the predictor and the response.
    
i. The strength of the relationship between the predictor and the response can be examined by using the numerical measures of model fit $RSE$ and $R^2$. For this model, the $RSE$ is `r auto_fit %>% glance() %>% pull(sigma)`. Based on the mean value of __mpg__ which is `r mean(ISLR2::Auto$mpg)`, we have a percentage error of `r auto_fit %>% glance() %>% pull(sigma) / mean(ISLR2::Auto$mpg) * 100`\%. In addition, the $R^2$ for the model is `r auto_fit %>% glance() %>% pull(r.squared)`, which indicates that the proportion of variance explained by the model is `r auto_fit %>% glance() %>% pull(r.squared)`\%. Thus, it appears that the linear relationship between __mpg__ and __horsepower__ is moderately strong.
    


